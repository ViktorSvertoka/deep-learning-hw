# -*- coding: utf-8 -*-
"""dz_topic_10_svertoka_viktor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bBdf9KpK6EnIsSUjLvvDcqrNmUFCMq_S
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report

import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Завантаження необхідних ресурсів nltk
nltk.download('stopwords')
nltk.download('punkt')

# Завантаження датасету
df = pd.read_csv('/content/spam.csv', encoding='latin-1')
df = df[['v1', 'v2']]
df.columns = ['label', 'text']

# Візуалізація кількості спам/не спам повідомлень
sns.countplot(x='label', data=df)

# Обробка тексту
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\W', ' ', text)               # видалити спецсимволи
    text = re.sub(r'\s+', ' ', text).strip()      # видалити зайві пробіли
    tokens = text.split()                         # проста токенізація
    filtered = [word for word in tokens if word not in stop_words]
    return ' '.join(filtered)

df['clean_text'] = df['text'].apply(preprocess_text)

# Розділення на X/y
X = df['clean_text']
y = df['label'].map({'ham': 0, 'spam': 1})

# Train/Test Split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Vectorizer: BoW
vectorizer_bow = CountVectorizer(max_features=3000, ngram_range=(1,2))
X_train_bow = vectorizer_bow.fit_transform(X_train)
X_val_bow = vectorizer_bow.transform(X_val)

# Vectorizer: TF-IDF
vectorizer_tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1,2))
X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)
X_val_tfidf = vectorizer_tfidf.transform(X_val)

# Logistic Regression — BoW
model_bow = LogisticRegression(max_iter=1000)
model_bow.fit(X_train_bow, y_train)
y_pred_bow = model_bow.predict(X_val_bow)

# Logistic Regression — TF-IDF
model_tfidf = LogisticRegression(max_iter=1000)
model_tfidf.fit(X_train_tfidf, y_train)
y_pred_tfidf = model_tfidf.predict(X_val_tfidf)

# Оцінка моделей
def evaluate_model(y_true, y_pred, model_name):
    acc = accuracy_score(y_true, y_pred)
    auc = roc_auc_score(y_true, y_pred)
    print(f"{model_name} — Accuracy: {acc:.4f}, AUC: {auc:.4f}")
    print(classification_report(y_true, y_pred))

evaluate_model(y_val, y_pred_bow, "BoW")
evaluate_model(y_val, y_pred_tfidf, "TF-IDF")

# --- GloVe Embeddings ---
# Скачування та розпакування GloVe (разово)
!wget -q http://nlp.stanford.edu/data/glove.6B.zip
!unzip -q glove.6B.zip

# Завантаження glove.6B.50d.txt
embedding_index = {}
with open("glove.6B.50d.txt", encoding="utf-8") as f:
    for line in f:
        values = line.split()
        word = values[0]
        vec = np.asarray(values[1:], dtype='float32')
        embedding_index[word] = vec

# Функція перетворення тексту в середній вектор
def get_embedding_vector(text):
    words = text.split()
    word_vecs = [embedding_index.get(word) for word in words if embedding_index.get(word) is not None]
    if word_vecs:
        return np.mean(word_vecs, axis=0)
    else:
        return np.zeros(50)

X_train_embed = np.vstack(X_train.apply(get_embedding_vector))
X_val_embed = np.vstack(X_val.apply(get_embedding_vector))

# Модель на GloVe embeddings
model_embed = RandomForestClassifier(n_estimators=100, random_state=42)
model_embed.fit(X_train_embed, y_train)
y_pred_embed = model_embed.predict(X_val_embed)

evaluate_model(y_val, y_pred_embed, "GloVe Embeddings")

# Таблиця результатів
results = pd.DataFrame({
    "Модель": ["BoW", "TF-IDF", "GloVe Embeddings"],
    "Accuracy": [
        accuracy_score(y_val, y_pred_bow),
        accuracy_score(y_val, y_pred_tfidf),
        accuracy_score(y_val, y_pred_embed)
    ],
    "AUC": [
        roc_auc_score(y_val, y_pred_bow),
        roc_auc_score(y_val, y_pred_tfidf),
        roc_auc_score(y_val, y_pred_embed)
    ]
})

print("\n=== Порівняння моделей ===")
print(results)

print("\n=== Аналіз результатів ===")
print("""
'''
Аналіз результатів класифікації спаму:

1. Загальний огляд:
Усі три моделі продемонстрували високу точність (Accuracy) — понад 96%, що свідчить про добру здатність класифікувати листи як спам або легітимні.

2. Порівняння моделей:
- Модель на основі BoW (Bag of Words) показала найкращі результати з Accuracy 98.0% та AUC 0.926. Вона має найвищий показник як точності, так і площі під ROC-кривою, що говорить про стабільність і якість класифікації.
- TF-IDF модель трохи поступається BoW, з Accuracy 97.3% та AUC 0.908, але все одно демонструє високі результати.
- Модель з використанням GloVe ембедингів має найнижчі показники Accuracy (96.4%) та AUC (0.869) серед трьох, проте вона показує добрий рівень, особливо враховуючи, що ембедингова модель враховує семантику слів.

3. Аналіз precision, recall, f1-score:
- В усіх моделях клас «ham» (легітимні повідомлення) класифікується дуже добре (recall близько 1.0).
- Для класу «spam» recall найнижчий у GloVe (0.74), що свідчить про пропуск деяких спам-листів. Найкращий recall для спаму у BoW (0.85).
- Це означає, що BoW модель краще виявляє спам, знижуючи ймовірність пропуску небажаних повідомлень.

4. Переваги та недоліки підходів:
- BoW і TF-IDF — прості та ефективні методи, які показують дуже високі результати на цій задачі.
- Ембедингова модель краще враховує контекст і семантику, але для даної задачі класифікації спаму, де важливі ключові слова та їх частота, вона показала трохи гірший результат.
- Ембедингова модель може краще працювати на складніших текстах або з меншим обсягом даних.

5. Висновок:
Для задачі класифікації спаму на цьому наборі даних найкращою виявилась модель з використанням BoW представлення тексту. Однак TF-IDF і GloVe також показали гідні результати, і їх можна використати як альтернативу або в ансамблях.

6. Рекомендації для покращення:
- Можна спробувати ансамблювати моделі для покращення точності.
- Провести тонке налаштування гіперпараметрів моделей.
- Застосувати більш складні нейронні архітектури на основі ембедингів.
- Розглянути балансування класів для покращення recall спаму.

7. Загалом, усі підходи є ефективними, але для цієї задачі і набору даних прості методи на основі BoW/TF-IDF демонструють кращий результат.
'''
""")